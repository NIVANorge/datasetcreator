{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% import\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dataclasses import  asdict\n",
    "from datetime import datetime, timedelta\n",
    "from dscreator.storage import get_storage_handler\n",
    "from dscreator.sources.ferrybox.extractor import TrajectoryExtractor, NamedTrajectory, NamedArray\n",
    "from sqlalchemy import create_engine\n",
    "from dscreator.config import SETTINGS\n",
    "from dscreator.datasets.trajectories.ferrybox import NorsoopFantasy\n",
    "from dscreator.sources.ferrybox.uuid_variable_code_mapper import MAPPER\n",
    "import numpy as np\n",
    "\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_manual_qc(traj_raw, boat, year) -> NamedTrajectory:\n",
    "    \"\"\"Helper to read and apply manually checked data to a named trajectory\n",
    "    \"\"\"\n",
    "    bad_ox = pd.read_csv(f'Norsoop-manual-qc-files/{boat}{year}_bad_ox_sat_dates.txt', header=None)\n",
    "    bad_T = pd.read_csv(f'Norsoop-manual-qc-files/{boat}{year}_bad_inletT_dates.txt', header=None)\n",
    "    bad_T = np.array([dt.to_pydatetime() for dt in pd.to_datetime(bad_T[bad_T.columns[0]]).to_list()])\n",
    "    bad_ox = np.array([dt.to_pydatetime() for dt in pd.to_datetime(bad_ox[bad_ox.columns[0]]).to_list()])\n",
    "    i_bad_T = np.intersect1d(np.array(traj_raw.datetime_list), bad_T, return_indices=True)[1]\n",
    "    i_bad_ox = np.intersect1d(np.array(traj_raw.datetime_list), bad_ox, return_indices=True)[1]\n",
    "    print(f\"Found {len(i_bad_T)} timestamp with no flow, and {len(i_bad_ox)} with bad oxygen\")\n",
    "    print(f\"{len(np.intersect1d(i_bad_T, i_bad_ox))} timestamps overlap\")\n",
    "    print(f\"About to set values for oxygen to None for bad oxygen timestamps\")\n",
    "    traj = NamedTrajectory(\n",
    "        array_list=[NamedArray(nta.variable_name, [None if i in i_bad_ox else val for i,val in enumerate(nta.values)])\n",
    "                    if nta.variable_name==\"Oxygen\" else nta for nta in traj_raw.array_list],\n",
    "        datetime_list=traj_raw.datetime_list,\n",
    "        locations=traj_raw.locations)\n",
    "\n",
    "    print(f\"About to remove bad flow data. Before removal size of data based on location is \"\n",
    "          f\"{len(traj.locations)}\")\n",
    "    traj = NamedTrajectory(\n",
    "        array_list=[NamedArray(nta.variable_name, list(np.delete(nta.values, i_bad_T)))\n",
    "                    for nta in traj.array_list],\n",
    "        datetime_list=list(np.delete(traj.datetime_list, i_bad_T)),\n",
    "        locations=list(np.delete(traj.locations, i_bad_T)))\n",
    "    print(f\"After removal size of data based on location is {len(traj.locations)}\")\n",
    "\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% input parameters\n"
    }
   },
   "outputs": [],
   "source": [
    "boat = \"FA\"\n",
    "measurement_parameters = [\"Temperature\", \"Salinity\", \"Oxygen\"]\n",
    "uuid=\"14bb8759-81d8-4a1a-948a-14219d374fab\"\n",
    "stationname=\"color_fantasy\"\n",
    "datasetname=f\"{stationname}_norsoop\"\n",
    "projectname=\"NorSoop\"\n",
    "\n",
    "tb = NorsoopFantasy(\n",
    "    uuid=uuid,\n",
    "    dataset_name=datasetname,\n",
    "    station_name=stationname,\n",
    "    project_name=projectname,\n",
    "    is_acdd=False\n",
    ")\n",
    "years = [2017, 2018, 2019, 2020, 2021, 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% fetch data\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting year 2017\n",
      "Found 11568 timestamp with no flow, and 12638 with bad oxygen\n",
      "6025 timestamps overlap\n",
      "About to set values for oxygen to None for bad oxygen timestamps\n",
      "About to remove bad flow data. Before removal size of data based on location is 351685\n",
      "After removal size of data based on location is 340117\n",
      "Dumped FA_2017_color_fantasy.nc\n",
      "Extracting year 2018\n",
      "Found 24961 timestamp with no flow, and 4276 with bad oxygen\n",
      "1409 timestamps overlap\n",
      "About to set values for oxygen to None for bad oxygen timestamps\n",
      "About to remove bad flow data. Before removal size of data based on location is 352954\n",
      "After removal size of data based on location is 327993\n",
      "Dumped FA_2018_color_fantasy.nc\n",
      "Extracting year 2019\n",
      "Found 23216 timestamp with no flow, and 454 with bad oxygen\n",
      "117 timestamps overlap\n",
      "About to set values for oxygen to None for bad oxygen timestamps\n",
      "About to remove bad flow data. Before removal size of data based on location is 323603\n",
      "After removal size of data based on location is 300387\n",
      "Dumped FA_2019_color_fantasy.nc\n",
      "Extracting year 2020\n",
      "Found 36714 timestamp with no flow, and 17492 with bad oxygen\n",
      "12133 timestamps overlap\n",
      "About to set values for oxygen to None for bad oxygen timestamps\n",
      "About to remove bad flow data. Before removal size of data based on location is 216554\n",
      "After removal size of data based on location is 179840\n",
      "Dumped FA_2020_color_fantasy.nc\n",
      "Extracting year 2021\n",
      "Found 1 timestamp with no flow, and 406 with bad oxygen\n",
      "0 timestamps overlap\n",
      "About to set values for oxygen to None for bad oxygen timestamps\n",
      "About to remove bad flow data. Before removal size of data based on location is 205104\n",
      "After removal size of data based on location is 205103\n",
      "Dumped FA_2021_color_fantasy.nc\n",
      "Extracting year 2022\n",
      "Found 7196 timestamp with no flow, and 404 with bad oxygen\n",
      "157 timestamps overlap\n",
      "About to set values for oxygen to None for bad oxygen timestamps\n",
      "About to remove bad flow data. Before removal size of data based on location is 343459\n",
      "After removal size of data based on location is 336263\n",
      "Dumped FA_2022_color_fantasy.nc\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(SETTINGS.database_url)\n",
    "variable_uuid_map = MAPPER[f\"{boat}_19\"]\n",
    "traj_extractor = TrajectoryExtractor(engine, measurement_parameters, variable_uuid_map)\n",
    "nc_paths = []\n",
    "for year in years:\n",
    "    print(f\"Extracting year {year}\")\n",
    "    if year == 2020:\n",
    "        variable_uuid_map = MAPPER[f\"{boat}_20\"]\n",
    "        traj_extractor = TrajectoryExtractor(engine, measurement_parameters, variable_uuid_map)\n",
    "\n",
    "    start_time = datetime(year, 1, 1, 0, 0, 0)\n",
    "    traj_raw = traj_extractor.fetch_slice(start_time=start_time, end_time=start_time + timedelta(days=365))\n",
    "    ds = tb.create(apply_manual_qc(traj_raw, boat, year))\n",
    "    # Store each year on disk after extraction\n",
    "    SETTINGS.storage_path = os.path.join(os.getcwd(), \"..\", \"catalog\")\n",
    "    sh = get_storage_handler(\n",
    "        project_name=datasetname,\n",
    "        dataset_name=stationname,\n",
    "        unlimited_dims=[\"time\"],\n",
    "        filename_prefix= f\"FA_{year}\"\n",
    "    )\n",
    "    fname = sh.save_dataset(ds)\n",
    "    print(f\"Dumped {fname.split('/')[-1]}\")\n",
    "    nc_paths.append(fname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge each year of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = xr.merge([xr.open_dataset(p) for p in nc_paths])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refresh attributes based on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.attrs = asdict(tb.dataset_attributes(ds))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTINGS.storage_path = \"gs://nivatest-1-senda\"\n",
    "sh = get_storage_handler(\n",
    "        project_name=projectname,\n",
    "        dataset_name=datasetname,\n",
    "        unlimited_dims=[\"time\"],\n",
    "        filename_prefix= f\"FA_merge\"\n",
    ")\n",
    "sh.save_dataset(ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
